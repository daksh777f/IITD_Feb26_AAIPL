{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480066b8",
   "metadata": {},
   "source": [
    "<h1 align='center'> Welcome to the AMD AI Premier League (AAIPL)! </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a566b-fa28-4a9f-8382-de6aeeacfcaf",
   "metadata": {},
   "source": [
    "<!-- <img src=\"./assets/aaipl.png\"> -->\n",
    "<img src=\"./assets/AMDAAIPL.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4b3fe",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Task\n",
    "You will be building:\n",
    "1.  **A question agent** that will ask $N$ puzzle-based questions based on provided [topics](./assets/topics.json).\n",
    "    - Create your model in [question_model.py](./agents/question_model.py) (it will be called by [question_agent.py](./agents/question_agent.py) for evaluation)\n",
    "    - *Your question agent must output questions in the format specified in [sample_question.json](./assets/sample_question.json)*.\n",
    "2. **An answer agent** that answers questions asked from a question agent.\n",
    "    -  Create your model in [answer_model.py](./agents/answer_model.py) (it will be called by [answer_agent.py](./agents/answer_agent.py) for evaluation)\n",
    "    -  *Your answer agent must output answers in the format specified in [sample_answer.json](./assets/sample_answer.json)*.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed3cfa0",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. How to initiate your workstation:\n",
    "    1. Go to **dev.amd-ai-academy.com**.\n",
    "    2. Type in the Team ID and Password from your printout.\n",
    "    3. Sign in.\n",
    "1. Read through this README.ipynb for more details on the challenge.\n",
    "    - **Note:** If members of your team are working from the notebook simultaneously, please coordinate to ensure you do not overwrite each other's work.\n",
    "1. You can **only** use the models provided in `/root/.cache/huggingface/hub`.\n",
    "    - These will be *read-only* - please **copy** a model you'd like to use into the `AAIPL/hf_models` folder. Here you can edit the model.\n",
    "    - If you attempt to change the models in the original folder, you will be **immediately disqualified**.\n",
    "1. Check out our [Synthetic Data Generation and Unsloth Tutorial](./tutorial.ipynb) for training tips and tricks.\n",
    "1. Before the deadline, kindly ensure that you push your code to Github (except `hf_models`).\n",
    "    - You can use the [`git.sh`](./git.sh) script to easily push it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd0427",
   "metadata": {},
   "source": [
    "##  Table of Contents:\n",
    "-  [Task](#task)\n",
    "-  [Instructions](#instructions)\n",
    "-  [Tournament Overview](#tournament-overview)\n",
    "-  [Guidelines](#guidelines)\n",
    "    - [Format](#format-overview)\n",
    "-  [Submission](#️what-you-will-submit)\n",
    "- WARNING: [Restrictions](#restrictions)\n",
    "-  [Directory & Files overview](#directory--files-overview)\n",
    "-  [Getting started](#getting-started)\n",
    "    -  [Env Setup](#env-setup)\n",
    "    -  [Q-Agent](#q-agent)\n",
    "        -  [Basic format-checks for questions from Q-agent](#basic-format-checks-for-questions-from-q-agent)\n",
    "    -  [A-agent](#a-agent)\n",
    "        -  [Basic format-checks for answers from A-agent](#basic-format-checks-for-answers-from-a-agent)\n",
    "-  [Evaluation](#evaluation)\n",
    "    -  [Scoring Criteria](#scoring-criteria)\n",
    "    -  [Scoring Example](#scoring-example)\n",
    "-  [Time Limit](#time-limit)\n",
    "<!-- -  [LeaderBoard UI/UX](#leaderboard-uiux) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386cb37",
   "metadata": {},
   "source": [
    "## Tournament Overview\n",
    "<!--   -->\n",
    "* All matches in this tournament will be **1v1** knockout format where two teams, Team-A vs Team-B, will compete with their Q-agent (question agent) and A-agent (answer agent). You can think of this as a cricket match or baseball game where teams will switch sides.\n",
    "  * Before the matchups begin, there will be an **elimination round** where we will test your A-Agent against a hidden set of questions. The teams' A-Agents that scores the highest on these seeding questions will move onto the elimination stage. \n",
    "* Like in cricket, each match has two innings:\n",
    "    -   1st inning:\n",
    "        *   $N$ Question from the Q-agent (Team-A) and their corresponding $N$ answers from the A-agent (Team-B).\n",
    "        *   Q-agent score (Team-A): Say, $40$\n",
    "        *   A-agent score (Team-B): $60$\n",
    "\n",
    "    -   2nd inning:\n",
    "        *   $N$ Question from the Q-agent (Team-B) and their respective $N$ responses from the A-agent (Team-A).\n",
    "        *   Q-agent score (Team-B): Say, $70$\n",
    "        *   A-agent score (Team-A): $30$\n",
    "    -   Final Score:\n",
    "        *   Team-A score $=$ 1st inning Q-agent score $+$ 2nd inning A-agent score $= 40 + 30 = 70$\n",
    "        *   Team-B score $=$ 1st inning A-agent score $+$ 2nd inning Q-agent score $= 60 + 70 = 130$\n",
    "    -   Winner: **Team-B** with a score of $130$.\n",
    "\n",
    "For more info on how scoring is done, refer to the [scoring criteria section](#scoring-criteria).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deab9cf",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "<!--   -->\n",
    "\n",
    "### Format\n",
    "We will only consider responses from the Q-agent and the A-agent which follow the below format.\n",
    "\n",
    "*Note*: While having an explanation/reasoning is a plus, not having them doesn't disqualify the question or answer being correct.\n",
    "\n",
    "#### Q-Agent\n",
    "Given a topic, the Q-agent should generate questions in the specified JSON format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"topic\": \"<Topic of the Question>\",\n",
    "    \"question\": \"<full question text>\",\n",
    "    \"choices\": [\n",
    "        \"A) <choice A text>\",\n",
    "        \"B) <choice B text>\",\n",
    "        \"C) <choice C text>\",\n",
    "        \"D) <choice D text>\"\n",
    "    ],\n",
    "    \"answer\": \"<correct choice letter only>\",\n",
    "    \"explanation\": \"brief explanation within 100 words for why the answer is correct\"\n",
    "}\n",
    "```\n",
    "\n",
    "The **\"Topic\"**, **\"Question\"**, **\"Choices\"**, and **\"Answer\"** will be verified for correctness.\n",
    "\n",
    "#### A-Agent\n",
    "Given a Question and Choices, A-agent should produce answer in the format of:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"answer\": \"<correct choice letter only>\",\n",
    "    \"reasoning\": \"brief reasoning within 100 words for why the answer is correct\"\n",
    "}\n",
    "```\n",
    "\n",
    "The **\"Answer\"** key will be compared with **\"Answer\"** from the opponent's Q-agent.\n",
    "\n",
    "**<u>Note</u>**: *Once again, we will **only** consider those responses from the Q-agent and the A-agent which follow the above format.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b858a803",
   "metadata": {},
   "source": [
    "## Submission\n",
    "<!--   -->\n",
    "You need to submit your code which should contain these main files:\n",
    "1. All work must be within the `AAIPL` folder. Do NOT change the folder name.\n",
    "1. No need to upload anything anywhere, we'll collect your agent code from your Jupyter Server at the end of the challenge.\n",
    "   1. The agents will be called by `python -m agents.question_agent` and `python -m agents.answer_agent`, respectively.\n",
    "1. ENSURE model checkpoint(s) (e.g., `model.safetensors` or `.pt` or `.pth`) is (are) loading and expected files are getting generated from Q-agent and A-agent, when inference is done.\n",
    "   1. Outputs must be saved to `outputs/questions.json` and `outputs/answers.json`, respectively.\n",
    "1. **<u>Note</u>: You are not required to generate any `.json` for us, we'll do that for you during evaluation setting a specific value to $N$.**\n",
    "\n",
    "You can test your submission by running the commands in the [Getting Started](#getting-started) section.\n",
    "\n",
    "<u><span style=\"color: blue\">Note</span></u>: These files will be checked for any hardcoding, RAG, or other unfair practices.<br>\n",
    "<u><span style=\"color: red\">Remarks / Caution</span></u>: A-agent is equally important as Q-agent. So, please do focus on both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1cc2ce",
   "metadata": {},
   "source": [
    "## Restrictions\n",
    "<!-- WARNING: -->\n",
    "\n",
    "1.  **<span style=\"color: red\">NO</span> LAST Minute Submission**: The submission deadline is strict. Any changes to your code after the deadline may disqualify your submission.\n",
    "1.  RAG (Retrieval Augmented Generation) techniques are not allowed.\n",
    "1.  Adversarial approaches will lead to disqualification, e.g. making A-agents hallucinate.\n",
    "1.  Usage of models other than what was provided will lead to disqualification.\n",
    "1.  Only English language is allowed for both Q-agent and A-agent.\n",
    "1.  Strictly stay within the `max_tokens` limits specified in `agen.yaml` & `qgen.yaml`. Other parameters can be changed.\n",
    "1.  Questions must pertain to the topics listed in `topics.json`.\n",
    "1.  Each question should be generated under `13 secs`. Questions exceeding this limit will not be considered.\n",
    "1.  Each answer should be generated under `9 secs`. Answers exceeding this limit will not be considered.\n",
    "\n",
    "Feel free to reach out in the Discord channel for any clarifications or questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b562cb4",
   "metadata": {},
   "source": [
    "## Directory & Files overview\n",
    "<!--   -->\n",
    "\n",
    "```plaintext\n",
    ".\n",
    "├── agents\n",
    "│   ├── question_model.py\n",
    "│   ├── question_model_llama.py (example code using Unsloth Llama)\n",
    "│   ├── question_agent.py\n",
    "│   ├── answer_model.py\n",
    "│   ├── answer_model_llama.py (example code using Unsloth Llama)\n",
    "│   └── answer_agent.py\n",
    "├── assets\n",
    "│   ├── topics_example.json # example questions w.r.t each topic\n",
    "│   ├── topics.json # Topics on which we require to generate questions\n",
    "│   ├── sample_question.json # File specifying expected format of questions generated\n",
    "│   └── sample_answer.json # Expected format of answers generated\n",
    "├── utils\n",
    "│   └── build_prompt.py # prompt-tuning scripts\n",
    "├── README.ipynb\n",
    "├── tutorial.ipynb # Synthetic Data Generation and Unsloth Tutorial\n",
    "├── tutorial_config.yaml # Config file for tutorial\n",
    "├── qgen.yaml # Generation specific parameters for Q-agent\n",
    "└── agen.yaml # Generation specific parameters for A-agent\n",
    "```\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2187a198",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "<!--   -->\n",
    "Let's get started with running the Q-agent and A-agent framework.\n",
    "\n",
    "### Environment Setup\n",
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e583a6",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Import basic packages\n",
    "import json\n",
    "from typing import Dict, Any, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fdb0b0",
   "metadata": {},
   "source": [
    "### Q-Agent\n",
    "<!--  -->\n",
    "You will update the model in `question_model.py`, which will be invoked by `question_agent.py`. In the provided skeleton, we have used the base Qwen3-4B model for Q-Agent but you should experiment with other models and techniques. Check out our [Synthetic Data Generation and Unsloth Tutorial](./tutorial.ipynb) for training tips and tricks.\n",
    "\n",
    "Generated questions must pertain to the topics mentioned in `topics.json` file. Additional topics will be added for the tournament finals.\n",
    "\n",
    "__Topics:__\n",
    "1.  `Logical Reasoning`: Syllogisms\n",
    "2.  `Puzzles`: Seating Arrangements (Linear, Circular)\n",
    "3.  `Blood Relations and Family Tree`: Puzzles involving generations and family tree logic\n",
    "4.  `Alphanumeric Series`: Mixed series questions\n",
    "\n",
    "Sample questions and answers are available in the [assets folder](./assets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f181848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the following code to generate questions.\n",
    "# For demo purpose, we have used the base Qwen3-4B model for Q-Agent. Participants are expected to improve upon this\n",
    "!python -m agents.question_agent \\\n",
    "    --output_file \"outputs/questions.json\" \\\n",
    "    --num_questions 20 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e511c33",
   "metadata": {},
   "source": [
    "#### Basic format-checks for questions from Q-agent\n",
    "\n",
    "Generated questions must follow the [format instructions](#format-overview). All questions generated from the Q-agent will be filtered and validated before being sent to the opponent's A-agent. We generate two version of questions, one is the raw, unfiltered one `questions.json` and the other is `filtered_questions.json` after passing through the below example filter. The full filtering and validation process is part of the judging system and is not demonstrated here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3770ec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/root/.cache/huggingface/hub/models--Qwen--Qwen3-4B'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQwen/Qwen3-4B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount_tokens_q\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Count the number of tokens using Qwen3-4B tokenizer\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py:1058\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m   1057\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m tokenizer_config = \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[32m   1060\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = tokenizer_config[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py:890\u001b[39m, in \u001b[36mget_tokenizer_config\u001b[39m\u001b[34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[39m\n\u001b[32m    887\u001b[39m     token = use_auth_token\n\u001b[32m    889\u001b[39m commit_hash = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    907\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:321\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    264\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    265\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    266\u001b[39m     **kwargs,\n\u001b[32m    267\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    270\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:566\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    563\u001b[39m     \u001b[38;5;66;03m# Any other Exception type should now be re-raised, in order to provide helpful error messages and break the execution flow\u001b[39;00m\n\u001b[32m    564\u001b[39m     \u001b[38;5;66;03m# (EntryNotFoundError will be treated outside this block and correctly re-raised if needed)\u001b[39;00m\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    568\u001b[39m resolved_files = [\n\u001b[32m    569\u001b[39m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    570\u001b[39m ]\n\u001b[32m    571\u001b[39m \u001b[38;5;66;03m# If there are any missing file and the flag is active, raise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:478\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    477\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    493\u001b[39m         snapshot_download(\n\u001b[32m    494\u001b[39m             path_or_repo_id,\n\u001b[32m    495\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    504\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    505\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1007\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    988\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    989\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1005\u001b[39m     )\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:1124\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1121\u001b[39m blob_path = os.path.join(storage_folder, \u001b[33m\"\u001b[39m\u001b[33mblobs\u001b[39m\u001b[33m\"\u001b[39m, etag)\n\u001b[32m   1122\u001b[39m pointer_path = _get_pointer_path(storage_folder, commit_hash, relative_filename)\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1125\u001b[39m os.makedirs(os.path.dirname(pointer_path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1127\u001b[39m \u001b[38;5;66;03m# if passed revision is not identical to commit_hash\u001b[39;00m\n\u001b[32m   1128\u001b[39m \u001b[38;5;66;03m# then revision has to be a branch name or tag name.\u001b[39;00m\n\u001b[32m   1129\u001b[39m \u001b[38;5;66;03m# In that case store a ref.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:215\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 30] Read-only file system: '/root/.cache/huggingface/hub/models--Qwen--Qwen3-4B'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B\", padding_side='left')\n",
    "\n",
    "def count_tokens_q(text: str) -> int:\n",
    "    \"\"\"Count the number of tokens using Qwen3-4B tokenizer\"\"\"\n",
    "    return len(tokenizer.encode(text, add_special_tokens=False))\n",
    "\n",
    "def filter_questions(questions: List[str|Dict[str, str|Any]]) -> List[Dict[str, str|Any]]:\n",
    "    def basic_checks(q2: Dict[str, str])->bool:\n",
    "        # check required keys\n",
    "        required_keys = ['topic', 'question', 'choices', 'answer']\n",
    "        if all((key in q2) for key in required_keys):\n",
    "            # check choices format\n",
    "            checks = all(isinstance(choice, str) and len(choice) > 2 and choice[0].upper() in 'ABCD' for choice in q2['choices'])\n",
    "            if isinstance(q2['choices'], list) and len(q2['choices']) == 4 and checks:\n",
    "                # check answer format\n",
    "                # Check token length\n",
    "                check_len = sum(count_tokens_q(q2[k]) for k in ['question', 'answer'])\n",
    "                check_len += sum(count_tokens_q(choice) for choice in q2['choices']) - 15\n",
    "                if check_len < 130:\n",
    "                    if check_len + count_tokens_q(q2.get('explanation', 'None')) <= 1024:\n",
    "                        # Extra Checks: (PLUS checks) len(q2['answer']) == 1 and q2['answer'].upper() in 'ABCD':\n",
    "                        if isinstance(q2['answer'], str):\n",
    "                            return True\n",
    "        return False\n",
    "    correct_format_question = []\n",
    "    for i, q in enumerate(questions):\n",
    "        if isinstance(q, dict):\n",
    "            if basic_checks(q):\n",
    "                correct_format_question.append(q)\n",
    "        elif isinstance(q, str):\n",
    "            try:\n",
    "                q1 = json.loads(q)\n",
    "                if basic_checks(q1):\n",
    "                    correct_format_question.append(q1)\n",
    "            except json.JSONDecodeError:\n",
    "                # If JSON decoding fails, skip this answer\n",
    "                print(f\"Skipping invalid JSON at index {i}: {q}\")\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    if len(correct_format_question) >= 0.5 * len(questions):\n",
    "        return correct_format_question\n",
    "    return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66e521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"outputs/questions.json\", \"r\") as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "filtered_questions = filter_questions(questions)\n",
    "\n",
    "with open(\"outputs/filtered_questions.json\", \"w\") as f:\n",
    "    json.dump(filtered_questions, f, indent=4)\n",
    "\n",
    "print(f\"Number of questions: {len(questions)}\")\n",
    "print(f\"Number of filtered questions: {len(filtered_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96209d",
   "metadata": {},
   "source": [
    "### A-agent\n",
    "<!--   -->\n",
    "You will update the model in `answer_model.py`, which will be invoked by `answer_agent.py`. In the provided skeleton, we have again used the base Qwen3-4B model for A-Agent but you should experiment with other models and techniques. Check out our [Synthetic Data Generation and Unsloth Tutorial](./tutorial.ipynb) for training tips and tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51af0a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Same instructions apply for the answer agent.\n",
    "# For demo purpose, we have used the base Qwen3-4B model for A-agent. Participants are expected to improve upon this.\n",
    "!python -m agents.answer_agent \\\n",
    "    --input_file \"outputs/filtered_questions.json\" \\\n",
    "    --output_file \"outputs/answers.json\" \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3891529b",
   "metadata": {},
   "source": [
    "#### Basic format-checks for answers from A-agent\n",
    "Generated answers must follow the [format instructions](#format-overview). The following filter is added into the `answer_agent.py`. Similar to before, two versions are saved, `answers.json` and `filtered_answers.json`. The latter is used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acad45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B\", padding_side='left')\n",
    "\n",
    "def count_tokens_a(text: str) -> int:\n",
    "    \"\"\"Count the number of tokens in the text using the agent's tokenizer\"\"\"\n",
    "    return len(tokenizer.encode(text, add_special_tokens=False))\n",
    "\n",
    "def filter_answers(ans: List[str|Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "    r\"\"\"Filter answers to ensure they are in the correct format\"\"\"\n",
    "    def basic_checks(a1: Dict[str, str])->bool:\n",
    "        # check required keys\n",
    "        required_keys = ['answer']\n",
    "        if all((key in a1) and isinstance(a1[key], str) for key in required_keys):\n",
    "            if len(a1['answer']) == 1 and (a1['answer'] not in 'ABCDabcd'):\n",
    "                    return False\n",
    "            check_len = count_tokens_a(a1['answer'])\n",
    "            if check_len < 50:\n",
    "                check_len += count_tokens_a(a1.get('reasoning', 'None'))\n",
    "                if check_len < 512:\n",
    "                    # check answer format - EXTRA checks\n",
    "                    # if len(a1['answer']) == 1 and a1['answer'].upper() in 'ABCD':\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    filtered_answers = []\n",
    "    for i, a in enumerate(ans):\n",
    "        if isinstance(a, dict):\n",
    "            if basic_checks(a):\n",
    "                filtered_answers.append(a)\n",
    "            else:\n",
    "                filtered_answers.append(None)\n",
    "        elif isinstance(a, str):\n",
    "            # Basic checks: at least with correct JSON format\n",
    "            try:\n",
    "                a1 = json.loads(a)\n",
    "                if basic_checks(a1):\n",
    "                    filtered_answers.append(a1)\n",
    "                else:\n",
    "                    filtered_answers.append(None)\n",
    "            except json.JSONDecodeError:\n",
    "                # If JSON decoding fails, skip this answer\n",
    "                print(f\"Skipping invalid JSON at index {i}: {a}\")\n",
    "                filtered_answers.append(None)\n",
    "                continue\n",
    "        else:\n",
    "            # If the answer is neither a dict nor a str, skip it\n",
    "            print(f\"Skipping unsupported type at index {i}: {type(a)}\")\n",
    "            filtered_answers.append(None)\n",
    "    return filtered_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4301d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"outputs/answers.json\", \"r\") as f:\n",
    "    answers = json.load(f)\n",
    "filtered_answers = filter_answers(answers)\n",
    "\n",
    "\n",
    "print(f\"Number of answers: {len(answers)}\")\n",
    "print(f\"Number of filtered answers: {len(filtered_answers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6a911",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "<!--   -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa2284",
   "metadata": {},
   "source": [
    "### Scoring Criteria\n",
    "\n",
    "<!--   -->\n",
    "\n",
    "Scores are assigned based on: out of $N$ questions from Q-agent, how many an A-agent can answer and vice-versa. *No negative marking for wrong answers.*\n",
    "\n",
    "$$\\text{A-agent Score} = \\dfrac{\\#\\ \\text{of questions correctly answered with expected format}}{N}\\times 100$$\n",
    "$$\\text{Q-agent Score} = \\dfrac{\\#\\ \\text{of questions incorrectly answered by A-agent}}{N}\\times 100$$\n",
    "\n",
    "\n",
    "$N$ denotes the number of filtered / format-correct questions. **Teams whose Q-agent fails to generate at least $50\\%$ of `num_questions` (where `num_questions` ranges from $2$ to $1000+$) of the questions correctly (as per [format-checking](#format-overview)) will be automatically disqualified.**<br>\n",
    "\n",
    "In case of **TIE**, closed benchmark questions will be used to evaluate the answer agents (A-agent) and rank the teams accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f7ccf",
   "metadata": {},
   "source": [
    "### Scoring Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c11592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scores...\n",
    "N = len(filtered_questions)\n",
    "assert N == len(filtered_answers), \"Number of questions and answers must match.\"\n",
    "num_correct_answers = len([1 for q,a in zip(filtered_questions, filtered_answers) if a is not None and q['answer'] == a['answer']])\n",
    "\n",
    "# Here the answer may be correct, but since q['answer'] is not an option letter is not there, we face problems\n",
    "# Below shown is one way of simple string parsing\n",
    "num_correct_answers = len([1 for q,a in zip(filtered_questions, filtered_answers) if a is not None and q['answer'][0] == a['answer']])\n",
    "\n",
    "a_score = num_correct_answers*100/(N+1e-9)\n",
    "q_score = (N-num_correct_answers)*100/(N+1e-9)\n",
    "# Announce the scores\n",
    "print(f\"Number of questions: {N}\")\n",
    "print(f\"Number of correct answers: {num_correct_answers}\")\n",
    "print(\"Scores:\")\n",
    "print(f\"Team B: A-agent score: {a_score:.2f}\")\n",
    "print(f\"Team A: Q-agent score: {q_score:.2f}\")\n",
    "print(f\"Innings 1 winner: {'Team A' if q_score > a_score else 'Team B' if q_score < a_score else 'Draw'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
